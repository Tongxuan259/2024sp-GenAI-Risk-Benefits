---
layout: post
title: LLM Agents  
lecture: W12-Team2-LLMAgents
lectureVersion: current
extraContent: 
notes: team-2
video: team-2
tags:
- Agent
desc: 2024-S22
term: 2024-seminarRead
categories:
- FMAdapt
---


## Required Readings: 

### A Survey on Large Language Model based Autonomous Agents
  + https://arxiv.org/abs/2308.11432
  + Autonomous agents have long been a prominent research focus in both academic and industry communities. Previous research in this field often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from human learning processes, and thus makes the agents hard to achieve human-like decisions. Recently, through the acquisition of vast amounts of web knowledge, large language models (LLMs) have demonstrated remarkable potential in achieving human-level intelligence. This has sparked an upsurge in studies investigating LLM-based autonomous agents. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of the field of LLM-based autonomous agents from a holistic perspective. More specifically, we first discuss the construction of LLM-based autonomous agents, for which we propose a unified framework that encompasses a majority of the previous work. Then, we present a comprehensive overview of the diverse applications of LLM-based autonomous agents in the fields of social science, natural science, and engineering. Finally, we delve into the evaluation strategies commonly used for LLM-based autonomous agents. Based on the previous studies, we also present several challenges and future directions in this field. To keep track of this field and continuously update our survey, we maintain a repository of relevant references at this https URL.

## More Readings: 


### Position Paper: Agent AI Towards a Holistic Intelligence
+ https://arxiv.org/abs/2403.00833
+ Qiuyuan Huang, Naoki Wake, Bidipta Sarkar, Zane Durante, Ran Gong, Rohan Taori, Yusuke Noda, Demetri Terzopoulos, Noboru Kuno, Ade Famoti, Ashley Llorens, John Langford, Hoi Vo, Li Fei-Fei, Katsu Ikeuchi, Jianfeng Gao
+ Recent advancements in large foundation models have remarkably enhanced our understanding of sensory information in open-world environments. In leveraging the power of foundation models, it is crucial for AI research to pivot away from excessive reductionism and toward an emphasis on systems that function as cohesive wholes. Specifically, we emphasize developing Agent AI -- an embodied system that integrates large foundation models into agent actions. The emerging field of Agent AI spans a wide range of existing embodied and agent-based multimodal interactions, including robotics, gaming, and healthcare systems, etc. In this paper, we propose a novel large action model to achieve embodied intelligent behavior, the Agent Foundation Model. On top of this idea, we discuss how agent AI exhibits remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. Furthermore, we discuss the potential of Agent AI from an interdisciplinary perspective, underscoring AI cognition and consciousness within scientific discourse. We believe that those discussions serve as a basis for future research directions and encourage broader societal engagement.


### Tool Use in LLMs 
+ https://zorazrw.github.io/files/WhatAreToolsAnyway.pdf
+ an overview of tool use in LLMs, including a formal definition of the tool-use paradigm, scenarios where LLMs leverage tool usage, and for which tasks this approach works well; it also provides an analysis of complex tool usage and summarize testbeds and evaluation metrics across LM tooling works



### Practices for Governing Agentic AI Systems
+ https://cdn.openai.com/papers/practices-for-governing-agentic-ai-systems.pdf
+ Agentic AI systems—AI systems that can pursue complex goals with limited direct supervision— are likely to be broadly useful if we can integrate them responsibly into our society. While such systems have substantial potential to help people more efficiently and effectively achieve their own goals, they also create risks of harm. In this white paper, we suggest a definition of agentic AI systems and the parties in the agentic AI system life-cycle, and highlight the importance of agreeing on a set of baseline responsibilities and safety best practices for each of these parties. As our primary contribution, we offer an initial set of practices for keeping agents’ operations safe and accountable, which we hope can serve as building blocks in the development of agreed baseline best practices. We enumerate the questions and uncertainties around operationalizing each of these practices that must be addressed before such practices can be codified. We then highlight categories of indirect impacts from the wide-scale adoption of agentic AI systems, which are likely to necessitate additional governance frameworks.



### Emergent autonomous scientific research capabilities of large language models
  + https://arxiv.org/abs/2304.05332
  + Transformer-based large language models are rapidly advancing in the field of machine learning research, with applications spanning natural language, biology, chemistry, and computer programming. Extreme scaling and reinforcement learning from human feedback have significantly improved the quality of generated text, enabling these models to perform various tasks and reason about their choices. In this paper, we present an Intelligent Agent system that combines multiple large language models for autonomous design, planning, and execution of scientific experiments. We showcase the Agent's scientific research capabilities with three distinct examples, with the most complex being the successful performance of catalyzed cross-coupling reactions. Finally, we discuss the safety implications of such systems and propose measures to prevent their misuse.


  
###   What Makes a Dialog Agent Useful?
+  https://huggingface.co/blog/dialog-agents


# In this session, our blog covers: 
##  A Survey on Large Language Model based Autonomous Agents
 <style>
  .container {
  display: flex;
  align-items: center;
  justify-content: center
}

img {
  max-width: 100%;
  max-height:100%;
}

.text {
  font-size: 20px;
  padding-left: 20px;
}
  </style>

### 1 &nbsp; &nbsp; Overview:
<img src="{{ site.baseurl }}/Lectures/S0-L22/images/p1/pic2.png" width="100%" height="100%">
This survey is a systematic review  for existing studies in the field of LLM-based agents and Focuses on three aspects:​
​
+ Agent construction​
+ Application, and​
+ Evaluation​


<img src="{{ site.baseurl }}/Lectures/S0-L22/images/p1/pic1.png" width="100%" height="100%">

### 2 &nbsp; &nbsp; LLM-based Autonomous Agent Construction:

LLM-based autonomous agents are expected to effectively perform diverse tasks by leveraging the
human-like capabilities of LLMs. In order to achieve
this goal, there are two significant aspects, that is,
(1) which architecture should be designed to better
use LLMs and (2) give the designed architecture,
how to enable the agent to acquire capabilities for
accomplishing specific tasks. In specific, the overall
structure of our framework is illustrated Figure 2.

<img src="{{ site.baseurl }}/Lectures/S0-L22/images/p1/pic3.png" width="100%" height="100%">


#### 2.1 &nbsp; Profiling Module:

<div class="container">
      <div class="image">
        <img src="{{ site.baseurl }}/Lectures/S0-L22/images/p1/pic5_pro.png" width="100%" height="100%">
      </div>
      <div class="text">
The profiling module aims to indicate the profiles of the agent roles, which are​
usually written into the prompt to influence the LLM behaviors.​
​
<br>
<b>Profile Contents:</b>​

<ul>
  <li> basic information such as age, gender, and career​​</li>
  <li> psychology information, reflecting the personalities of the agents​
</li>
<li>social information, detailing the relationships between agents​

</li>

</ul>

<br>
<b>Generation Strategies:</b>
 <ol>
  <li> <b>Handcrafting Method</b>:  Agent profiles are manually specified.​ For instance, if one would like to design agents with different personalities, he can use ”you are an outgoing person” or ”you are an introverted person” to profile the agent.​</li>
  <li> <b>LLM-generation Method</b>:  Agent profiles are automatically generated based on LLMs. Typically, it begins by indicating the profile generation rules, elucidating the composition and attributes of the agent profiles​ within the target population. ​
</li>
<li><b>Dataset Alignment Method</b> :  Here, agent profiles are obtained from real-world datasets. 
</li>

</ol>

      </div>
</div>

#### 2.2 &nbsp; Memory Module:
<div class="container">
      <div class="image">
        <img src="{{ site.baseurl }}/Lectures/S0-L22/images/p1/pic6_memory.png" width="100%" height="100%">
      </div>
      <div class="text">
The memory module can help the agent to accumulate experiences, self-evolve,​
and behave in a more consistent, reasonable, and effective manner.​

<br>
​

<b>Memory Structures: ​</b>​

​<ol>
  <li><b>Unified Memory</b>​: It simulates the human short-term memory​

usually realized by in-context learning, and​

the memory information is directly written into the prompts​​</li>
  <li><b>Hybrid Memory</b>​: This structure explicitly models the human short-term and long-term memories.​

short-term memory temporarily buffers recent perceptions​

long-term memory consolidates important information over time​ </li>

</ol>


​<br>

<b> Memory Formats: ​</b>​

​<ol>
  <li><b>Natural Languages</b>​: In this format, memory information are directly described using raw​
natural language.​​</li>
  <li><b>Embeddings</b>​: In this format, memory information is encoded into​
embedding vectors. It enhance the memory retrieval and reading efficiency.​</li>
  <li><b>Databases</b>​:  In this format, memory information is stored in databases, allowing the agent to manipulate memories efficiently and comprehensively​​</li>
  <li><b>Structured Lists</b>​: In this format, memory information is organized into​
lists, and the semantic of memory can be conveyed in an efficient and​
concise manner.​​</li>
</ol>

<br>

<b> Memory Operations: ​</b>​

​<ol>
  <li><b>Memory Reading</b>​: The objective of memory reading is to extract​
meaningful information from memory to enhance the agent’s actions.​
For example, using the previously successful actions to achieve similar​
goals. The following equation from existing literature for memory information​
extraction.​
<img src="{{ site.baseurl }}/Lectures/S0-L22/images/p1/pic4.png" width="100%" height="100%">

​​</li>
  <li><b>Memory Writing</b>​: The purpose of memory writing is to store​
information about the perceived environment in memory. there are two​
potential problems that should be carefully addressed a) Memory Duplicated and b) Memory Overflow​​</li>
  <li><b>Memory Reflection</b>​:  To independently summarize and infer more abstract,​
complex and high-level information.​​</li>

</ol>

​
      </div>
</div>



#### 2.3 &nbsp; Planning Module:
<div class="container">
      <div class="image">
        <img src="{{ site.baseurl }}/Lectures/S0-L22/images/p1/pic7_planning.png" width="100%" height="100%">
      </div>
      <div class="text">
The planning module aims to empower the agents with human capability of deconstructing a ​

task into subtasks, which is expected to make the agent behave more reasonably, powerfully, ​

and reliably.

<br>
<b>Planning without Feedback:</b>​

<ol>
  <li><b> Single-path Reasoning</b>: In this strategy, the
final task is decomposed into several intermediate
steps. These steps are connected in a cascading manner, with each step leading to only one subsequent
step. LLMs follow these steps to achieve the final
goal.​</li>
  <li> <b>Multi-path Reasoning</b>: In this strategy, the
reasoning steps for generating the final plans are
organized into a tree-like structure. Each intermediate step may have multiple subsequent steps. This
approach is analogous to human thinking, as individuals may have multiple choices at each reasoning
step
</li>
<li><b>External Planner</b>: Despite the demonstrated
power of LLMs in zero-shot planning, effectively
generating plans for domain-specific problems remains highly challenging. To address this challenge,
researchers turn to external planners. These tools
are well-developed and employ efficient search algorithms to rapidly identify correct, or even optimal,
plans. 

</li>

</ol>

<br>
<b>Planning with Feedback:</b>
To tackle complex human tasks, individual​
agents may iteratively make and revise their plans based on external​
feedback.​
​<br>
 <ol>
  <li> <b>Environmental Feedback</b>:  This feedback is obtained from the​
objective world or virtual environment. ​​</li>
  <li> <b>Human Feedback</b>:  Directly Interacting with humans is also a very​
intuitive strategy to enhance the agent planning capability.
</li>
<li><b>Model Feedback</b> : Apart from the aforementioned environmental and​
human feedback, which are external signals, researchers have also​
investigated the utilization of internal feedback from the agents​
themselves.
</li>

</ol>

      </div>
</div>



#### 2.3 &nbsp; Action Module:
<div class="container">
      <div class="image">
        <img src="{{ site.baseurl }}/Lectures/S0-L22/images/p1/pic8_action.png" width="100%" height="100%">
      </div>
      <div class="text">
 The action module is responsible for translating the agent’s​
decisions into specific outcomes. 

<br>
<b> Action goal:</b>​
 what are
the intended outcomes of the actions?
<ol>
  <li><b> Task Completion</b>: In this
scenario, the agent’s actions are aimed at accomplishing specific tasks, such as crafting an iron pickaxe in Minecraft.​</li>
  <li> <b>Communication</b>: In this
case, the actions are taken to communicate with the
other agents or real humans for sharing information or collaboration. For example, the agents in
ChatDev may communicate with each other
to collectively accomplish software development
tasks. 
</li>
<li><b>Exploration</b>: In this example, the
agent aims to explore unfamiliar environments to
expand its perception and strike a balance between
exploring and exploiting. For instance, the agent in
Voyager may explore unknown skills in their
task completion process, and continually refine the
skill execution code based on environment feedback
through trial and error.

</li>

</ol>
  
<br>
<b>Action Production:</b>
 how are the actions generated?
​<br>
 <ol>
  <li> <b>Action via Memory Recollection</b>:  In this strategy, the action is generated by extracting information from the agent ​
memory according to the current task. The task and the extracted memories are ​
used as prompts to trigger the agent actions.​ ​​</li>

<li><b>Action via Plan Following </b> : In this strategy, the agent takes actions​
following its pre-generated plan.​
</li>

</ol>


<br>
<b>Action space:</b>
 what are the available actions?​
​<br>
 <ol>
  <li> <b>External Tools</b>:  API, Databases Knowledge Bases, External Models.​​ ​​</li>

<li><b>Internal Knowledge </b> : Planning Capability, Conversation​
Capability and Common Sense Understanding Capability.​
</li>

</ol>


​
<br>
<b>Action impact:</b>
what are the consequences of the actions?​
​<br>
 <ol>
  <li> <b>Changing Environments</b>: Agents can directly alter environment states​
by actions, such as moving their positions, collecting items, constructing​
buildings, etc​​​</li>

<li><b>Altering Internal States</b> : Actions taken by the agent can also change​
the agent itself, including updating memories, forming new plans,​
acquiring novel knowledge, and more.​
</li>

<li><b>Triggering New Actions</b> :In the task completion process, one agent​
action can be triggered by another one.
</li>
</ol>


      </div>
</div>